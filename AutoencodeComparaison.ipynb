{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a727051",
   "metadata": {},
   "source": [
    "# V / Modélisation avec l'algorithme Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00f52a",
   "metadata": {},
   "source": [
    "## V.1 ) Classification Binaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.ndimage import zoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and preprocess NIfTI images\n",
    "def load_and_preprocess_images_nifti_batch(image_paths, target_size):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        img = nib.load(image_path).get_fdata()\n",
    "        img_resized = zoom(img, target_size / np.array(img.shape), order=1)\n",
    "        images.append(img_resized)\n",
    "    return np.array(images)\n",
    "\n",
    "# Set directories and file paths\n",
    "image_dir = 'E:/StageEsprit/ADNI_CNN_Transfer_Autoencoder/annual_screening/annual/ADNI/CN,AD,MCI'\n",
    "excel_path = 'E:/StageEsprit/ADNI_CNN_Transfer_Autoencoder/ADNI1_Annual_2_Yr_3T_8_05_2023 - Copie.xlsx'\n",
    "\n",
    "# Load labels from Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# List of allowed image extensions\n",
    "image_extensions = ['.nii', '.nii.gz']\n",
    "\n",
    "# List to store image paths\n",
    "image_paths = []\n",
    "\n",
    "# Collect image paths from the directory\n",
    "for file_name in os.listdir(image_dir):\n",
    "    if any(file_name.lower().endswith(ext) for ext in image_extensions):\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "# Target size for image resizing\n",
    "target_size_reduced = (224, 224, 3)\n",
    "\n",
    "# Batch size for loading images\n",
    "batch_size = 5\n",
    "\n",
    "# Split image paths into batches\n",
    "image_batches = [image_paths[i:i + batch_size] for i in range(0, len(image_paths), batch_size)]\n",
    "\n",
    "# Load and preprocess images in batches\n",
    "images_nifti = []\n",
    "y_labels = []\n",
    "\n",
    "for batch_paths in image_batches:\n",
    "    batch_images = load_and_preprocess_images_nifti_batch(batch_paths, target_size_reduced)\n",
    "    images_nifti.append(batch_images)\n",
    "\n",
    "    batch_labels = []\n",
    "    for image_path in batch_paths:\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        matching_rows = df[df['Subject'].str.contains(image_name)]['Group']\n",
    "        if len(matching_rows) > 0:\n",
    "            label = matching_rows.values[0]\n",
    "            if label == 'CN':\n",
    "                batch_labels.append(0)\n",
    "            else:\n",
    "                batch_labels.append(1)\n",
    "            \n",
    "\n",
    "    y_labels.extend(batch_labels)\n",
    "\n",
    "images_nifti = np.concatenate(images_nifti, axis=0)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "\n",
    "# Split data into train, test, and validation sets (70% train, 30% test)\n",
    "train_images, test_images, y_train, y_test = train_test_split(images_nifti, y_labels, test_size=0.3, random_state=42)\n",
    "test_images, val_images, y_test, y_val = train_test_split(test_images, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encoder part of the autoencoder\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "autoencoder = tf.keras.Sequential()\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# Decoder part of the autoencoder\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "# Compile autoencoder with adjusted learning rate\n",
    "#autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='mse', metrics=['accuracy'])\n",
    "autoencoder.compile(loss='mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Normalize the pixel values to [0, 1] range\n",
    "train_images_normalized = train_images / 255.0\n",
    "test_images_normalized = test_images / 255.0\n",
    "val_images_normalized = val_images / 255.0\n",
    "\n",
    "# Train the autoencoder on the normalized training images with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "history = autoencoder.fit(train_images_normalized, train_images_normalized, batch_size=32, epochs=10, shuffle=True, validation_data=(val_images_normalized, val_images_normalized), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract encoded representations of the training and test images\n",
    "encoded_train_images = autoencoder.predict(train_images)\n",
    "encoded_test_images = autoencoder.predict(test_images)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Reshape the encoded images to 2D arrays\n",
    "encoded_train_images_flattened = encoded_train_images.reshape(encoded_train_images.shape[0], -1)\n",
    "encoded_test_images_flattened = encoded_test_images.reshape(encoded_test_images.shape[0], -1)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', C=10, class_weight='balanced')\n",
    "\n",
    "# Train the SVM classifier on the flattened encoded representations\n",
    "svm_classifier.fit(encoded_train_images_flattened, y_train)\n",
    "\n",
    "# Predict using the SVM classifier\n",
    "svm_predictions = svm_classifier.predict(encoded_test_images_flattened)\n",
    "\n",
    "# Calculate evaluation metrics for SVM classifier\n",
    "accuracy = accuracy_score(y_test, svm_predictions)\n",
    "precision = precision_score(y_test, svm_predictions, average='weighted',zero_division = 1)\n",
    "recall = recall_score(y_test, svm_predictions, average='weighted',zero_division = 1)\n",
    "f1 = f1_score(y_test, svm_predictions, average='weighted',zero_division = 1)\n",
    "conf_matrix = confusion_matrix(y_test, svm_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92d723",
   "metadata": {},
   "source": [
    "## Affichage des images de test en classification binaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71410db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Nouvelles dimensions pour l'affichage des images\n",
    "display_width = 8\n",
    "display_height = 10\n",
    "\n",
    "# Calcul du nombre de colonnes en fonction du nombre d'images et des dimensions d'affichage\n",
    "num_cols = 8\n",
    "num_rows = math.ceil(len(test_images) / num_cols)\n",
    "\n",
    "# Création de la grille pour afficher les images\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(display_width * num_cols, display_height * num_rows))\n",
    "\n",
    "# Mapping des noms de classes aux étiquettes\n",
    "class_names = {0: 'Non Alzheimer (CN)', 1: 'Alzheimer'}\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(test_images):\n",
    "        img = convert_to_grayscale(test_images[i])\n",
    "        predicted_label = svm_predictions[i]\n",
    "        \n",
    "        ax.imshow(img, cmap='gray')  # Display in grayscale\n",
    "        \n",
    "        predicted_class = class_names[predicted_label]\n",
    "        \n",
    "        ax.set_title(f\"Prédiction: {predicted_class}\", fontsize=35)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d66ced",
   "metadata": {},
   "source": [
    "## Affichage des images originales et de reconstruction en classification binaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd27423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert RGB images to grayscale\n",
    "def convert_to_grayscale(images):\n",
    "    return np.dot(images[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# Get the reconstructed images from all test images\n",
    "reconstructed_images = autoencoder.predict(test_images_normalized)\n",
    "\n",
    "# Set the number of rows and columns for the grid\n",
    "num_rows = 2\n",
    "num_columns = 3\n",
    "num_images_to_display = num_rows * num_columns\n",
    "\n",
    "# Create a figure and subplots\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    # Original image\n",
    "    plt.subplot(num_rows, 2 * num_columns, 2 * i + 1)\n",
    "    plt.imshow(convert_to_grayscale(test_images[i]), cmap='gray')\n",
    "    plt.title(\"Original\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Reconstructed image\n",
    "    plt.subplot(num_rows, 2 * num_columns, 2 * i + 2)\n",
    "    plt.imshow(convert_to_grayscale(reconstructed_images[i]), cmap='gray')\n",
    "    plt.title(\"Reconstructed\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d5afd",
   "metadata": {},
   "source": [
    "## Calcul de l'erreur de reconstruction (mse) en classification binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error (MSE) between original and reconstructed images\n",
    "mse = np.mean(np.square(test_images_normalized - reconstructed_images))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482bbae4",
   "metadata": {},
   "source": [
    "## V.2) Classification Multiclasse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78680024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.ndimage import zoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and preprocess NIfTI images\n",
    "def load_and_preprocess_images_nifti_batch(image_paths, target_size):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        img = nib.load(image_path).get_fdata()\n",
    "        img_resized = zoom(img, target_size / np.array(img.shape), order=1)\n",
    "        images.append(img_resized)\n",
    "    return np.array(images)\n",
    "\n",
    "# Set directories and file paths\n",
    "image_dir = 'E:/StageEsprit/ADNI_CNN_Transfer_Autoencoder/annual_screening/annual/ADNI/CN,AD,MCI'\n",
    "excel_path = 'E:/StageEsprit/ADNI_CNN_Transfer_Autoencoder/ADNI1_Annual_2_Yr_3T_8_05_2023 - Copie.xlsx'\n",
    "\n",
    "# Load labels from Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# List of allowed image extensions\n",
    "image_extensions = ['.nii', '.nii.gz']\n",
    "\n",
    "# List to store image paths\n",
    "image_paths = []\n",
    "\n",
    "# Collect image paths from the directory\n",
    "for file_name in os.listdir(image_dir):\n",
    "    if any(file_name.lower().endswith(ext) for ext in image_extensions):\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "# Target size for image resizing\n",
    "target_size_reduced = (224, 224, 3)\n",
    "\n",
    "# Batch size for loading images\n",
    "batch_size = 5\n",
    "\n",
    "# Split image paths into batches\n",
    "image_batches = [image_paths[i:i + batch_size] for i in range(0, len(image_paths), batch_size)]\n",
    "\n",
    "# Load and preprocess images in batches\n",
    "images_nifti = []\n",
    "y_labels = []\n",
    "\n",
    "for batch_paths in image_batches:\n",
    "    batch_images = load_and_preprocess_images_nifti_batch(batch_paths, target_size_reduced)\n",
    "    images_nifti.append(batch_images)\n",
    "\n",
    "    batch_labels = []\n",
    "    for image_path in batch_paths:\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        matching_rows = df[df['Subject'].str.contains(image_name)]['Group']\n",
    "        if len(matching_rows) > 0:\n",
    "            label = matching_rows.values[0]\n",
    "            if label == 'CN':\n",
    "                batch_labels.append(0)\n",
    "            elif label == 'AD':\n",
    "                batch_labels.append(1)\n",
    "            elif label == 'MCI':\n",
    "                batch_labels.append(2)\n",
    "\n",
    "    y_labels.extend(batch_labels)\n",
    "\n",
    "images_nifti = np.concatenate(images_nifti, axis=0)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "\n",
    "# Split data into train, test, and validation sets (60% train, 20% test, 20% validation)\n",
    "train_images, test_images, y_train, y_test = train_test_split(images_nifti, y_labels, test_size=0.4, random_state=42)\n",
    "test_images, val_images, y_test, y_val = train_test_split(test_images, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Encoder part of the autoencoder\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "autoencoder = tf.keras.Sequential()\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# Decoder part of the autoencoder\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(3, (3, 3), activation='softmax', padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "# Compile autoencoder with adjusted learning rate\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Normalize the pixel values to [0, 1] range\n",
    "train_images_normalized = train_images / 255.0\n",
    "test_images_normalized = test_images / 255.0\n",
    "val_images_normalized = val_images / 255.0\n",
    "\n",
    "# Train the autoencoder on the normalized training images with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "history = autoencoder.fit(train_images_normalized, train_images_normalized, batch_size=64, epochs=20, shuffle=True, \n",
    "                          validation_data=(val_images_normalized, val_images_normalized), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract encoded representations of the training and test images\n",
    "encoded_train_images = autoencoder.predict(train_images)\n",
    "encoded_test_images = autoencoder.predict(test_images)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Reshape the encoded images to 2D arrays\n",
    "encoded_train_images_flattened = encoded_train_images.reshape(encoded_train_images.shape[0], -1)\n",
    "encoded_test_images_flattened = encoded_test_images.reshape(encoded_test_images.shape[0], -1)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', C=10, class_weight='balanced')\n",
    "\n",
    "# Train the SVM classifier on the flattened encoded representations\n",
    "svm_classifier.fit(encoded_train_images_flattened, y_train)\n",
    "\n",
    "# Predict using the SVM classifier\n",
    "svm_predictions = svm_classifier.predict(encoded_test_images_flattened)\n",
    "\n",
    "# Calculate evaluation metrics for SVM classifier\n",
    "accuracy = accuracy_score(y_test, svm_predictions)\n",
    "precision = precision_score(y_test, svm_predictions, average='weighted')\n",
    "recall = recall_score(y_test, svm_predictions, average='weighted')\n",
    "f1 = f1_score(y_test, svm_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, svm_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a0132",
   "metadata": {},
   "source": [
    "## Affichage des images de test en classification multiclasse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e452835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Nouvelles dimensions pour l'affichage des images\n",
    "display_width = 8\n",
    "display_height = 10\n",
    "\n",
    "# Calcul du nombre de colonnes en fonction du nombre d'images et des dimensions d'affichage\n",
    "num_cols = 8\n",
    "num_rows = math.ceil(len(test_images) / num_cols)\n",
    "\n",
    "# Création de la grille pour afficher les images\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(display_width * num_cols, display_height * num_rows))\n",
    "\n",
    "# Mapping des noms de classes aux étiquettes\n",
    "class_names = {0: 'Non Alzheimer (CN)', 1: 'Alzheimer (AD)', 2: 'Alzheimer (MCI)'}\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(test_images):\n",
    "        img = convert_to_grayscale(test_images[i])\n",
    "        predicted_label = svm_predictions[i]\n",
    "        \n",
    "        ax.imshow(img, cmap='gray')  # Display in grayscale\n",
    "        \n",
    "        predicted_class = class_names[predicted_label]\n",
    "        \n",
    "        ax.set_title(f\"Prédiction: {predicted_class}\", fontsize=35)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d86227",
   "metadata": {},
   "source": [
    "## Affichage des images originales et de reconstruction en classification multiclasse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1098e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert RGB images to grayscale\n",
    "def convert_to_grayscale(images):\n",
    "    return np.dot(images[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# Get the reconstructed images from all test images\n",
    "reconstructed_images = autoencoder.predict(test_images_normalized)\n",
    "\n",
    "# Set the number of rows and columns for the grid\n",
    "num_rows = 2\n",
    "num_columns = 4\n",
    "num_images_to_display = num_rows * num_columns\n",
    "\n",
    "# Randomly choose indices for images to display\n",
    "random_indices = np.random.choice(len(test_images), num_images_to_display, replace=False)\n",
    "\n",
    "# Create a figure and subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Original image\n",
    "    plt.subplot(num_rows, 2 * num_columns, 2 * i + 1)\n",
    "    plt.imshow(convert_to_grayscale(test_images[idx]), cmap='gray')\n",
    "    plt.title(\"Original\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Reconstructed image\n",
    "    plt.subplot(num_rows, 2 * num_columns, 2 * i + 2)\n",
    "    plt.imshow(convert_to_grayscale(reconstructed_images[idx]), cmap='gray')\n",
    "    plt.title(\"Reconstructed\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6132d7b",
   "metadata": {},
   "source": [
    "## Calcul de l'erreur de reconstruction (mse) en classification multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error (MSE) between original and reconstructed images\n",
    "mse = np.mean(np.square(test_images_normalized - reconstructed_images))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edfc22",
   "metadata": {},
   "source": [
    "# VI.1) Comparaison entre les modèles pour la classificatoin binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les métriques pour chaque algorithme\n",
    "accuracy_cnn = 0.7973856209150327  # Remplacez par la valeur de l'accuracy pour CNN\n",
    "precision_cnn = 0.8354430379746836 # Remplacez par la valeur de la precision pour CNN\n",
    "recall_cnn = 0.7857142857142857   # Remplacez par la valeur du recall pour CNN\n",
    "f1_cnn = 0.8098159509202455  # Remplacez par la valeur du F1-score pour CNN\n",
    "\n",
    "\n",
    "accuracy_transfer = 0.8608695652173913  # Remplacez par la valeur de l'accuracy pour Transfer Learning\n",
    "precision_transfer = 0.8947368421052632  # Remplacez par la valeur de la precision pour Transfer Learning\n",
    "recall_transfer = 0.8360655737704918  # Remplacez par la valeur du recall pour Transfer Learning\n",
    "f1_transfer = 0.864406779661017   # Remplacez par la valeur du F1-score pour Transfer Learning\n",
    "\n",
    "accuracy_autoencoder = 0.7543859649122807  # Remplacez par la valeur de l'accuracy pour Autoencoder\n",
    "precision_autoencoder = 0.779337231968811   # Remplacez par la valeur de la precision pour Autoencoder\n",
    "recall_autoencoder = 0.7543859649122807  # Remplacez par la valeur du recall pour Autoencoder\n",
    "f1_autoencoder = 0.758572567783094  # Remplacez par la valeur du F1-score pour Autoencoder\n",
    "\n",
    "\n",
    "# Créer le graphe à barres avec les métriques définies ci-dessus\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Métriques pour les trois algorithmes\n",
    "algorithms = ['CNN', 'Transfer Learning', 'Autoencoder']\n",
    "accuracy_scores = [accuracy_cnn, accuracy_transfer, accuracy_autoencoder]\n",
    "precision_scores = [precision_cnn, precision_transfer, precision_autoencoder]\n",
    "recall_scores = [recall_cnn, recall_transfer, recall_autoencoder]\n",
    "f1_scores = [f1_cnn, f1_transfer, f1_autoencoder]\n",
    "\n",
    "# Créer une figure avec plusieurs sous-graphiques\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "# Métrique : Accuracy\n",
    "axes[0, 0].bar(algorithms, accuracy_scores, color='blue')\n",
    "axes[0, 0].set_title('Accuracy')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : Precision\n",
    "axes[0, 1].bar(algorithms, precision_scores, color='green')\n",
    "axes[0, 1].set_title('Precision')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : Recall\n",
    "axes[1, 0].bar(algorithms, recall_scores, color='orange')\n",
    "axes[1, 0].set_title('Recall')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : F1-Score\n",
    "axes[1, 1].bar(algorithms, f1_scores, color='red')\n",
    "axes[1, 1].set_title('F1-Score')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "# Ajuster l'espacement entre les sous-graphiques\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher le graphe\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03730cb1",
   "metadata": {},
   "source": [
    "# VI.2) Comparaison entre les modèles pour la classificatoin multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les métriques pour chaque algorithme\n",
    "accuracy_cnn = 0.7189542483660131  # Remplacez par la valeur de l'accuracy pour CNN\n",
    "precision_cnn = 0.6790242165242165 # Remplacez par la valeur de la precision pour CNN\n",
    "recall_cnn = 0.6504667998356638   # Remplacez par la valeur du recall pour CNN\n",
    "f1_cnn = 0.6604542573275766  # Remplacez par la valeur du F1-score pour CNN\n",
    "\n",
    "accuracy_transfer = 0.8173913043478261  # Remplacez par la valeur de l'accuracy pour Transfer Learning\n",
    "precision_transfer = 0.8157886634967331  # Remplacez par la valeur de la precision pour Transfer Learning\n",
    "recall_transfer = 0.8173913043478261  # Remplacez par la valeur du recall pour Transfer Learning\n",
    "f1_transfer = 0.8124937531234382   # Remplacez par la valeur du F1-score pour Transfer Learning\n",
    "\n",
    "accuracy_autoencoder = 0.6842105263157895  # Remplacez par la valeur de l'accuracy pour Autoencoder\n",
    "precision_autoencoder = 0.687427997761759   # Remplacez par la valeur de la precision pour Autoencoder\n",
    "recall_autoencoder = 0.6842105263157895  # Remplacez par la valeur du recall pour Autoencoder\n",
    "f1_autoencoder = 0.6782862205299879  # Remplacez par la valeur du F1-score pour Autoencoder\n",
    "\n",
    "\n",
    "# Créer le graphe à barres avec les métriques définies ci-dessus\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Métriques pour les trois algorithmes\n",
    "algorithms = ['CNN', 'Transfer Learning', 'Autoencoder']\n",
    "accuracy_scores = [accuracy_cnn, accuracy_transfer, accuracy_autoencoder]\n",
    "precision_scores = [precision_cnn, precision_transfer, precision_autoencoder]\n",
    "recall_scores = [recall_cnn, recall_transfer, recall_autoencoder]\n",
    "f1_scores = [f1_cnn, f1_transfer, f1_autoencoder]\n",
    "\n",
    "# Créer une figure avec plusieurs sous-graphiques\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "# Métrique : Accuracy\n",
    "axes[0, 0].bar(algorithms, accuracy_scores, color='blue')\n",
    "axes[0, 0].set_title('Accuracy')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : Precision\n",
    "axes[0, 1].bar(algorithms, precision_scores, color='green')\n",
    "axes[0, 1].set_title('Precision')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : Recall\n",
    "axes[1, 0].bar(algorithms, recall_scores, color='orange')\n",
    "axes[1, 0].set_title('Recall')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# Métrique : F1-Score\n",
    "axes[1, 1].bar(algorithms, f1_scores, color='red')\n",
    "axes[1, 1].set_title('F1-Score')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "# Ajuster l'espacement entre les sous-graphiques\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher le graphe\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259dbd0",
   "metadata": {},
   "source": [
    "# VII.1) Interprétation des résultats pour la classificatoin binaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30c927",
   "metadata": {},
   "source": [
    "Les trois modèles, à savoir le CNN, le Transfer Learning et l'Autoencoder, ont été évalués en termes \n",
    "de leurs performances dans une tâche de classification binaire. En comparant leurs métriques clés, \n",
    "nous pouvons observer ce qui suit :\n",
    "\n",
    "\n",
    "CNN : Le modèle Convolutional Neural Network (CNN) a obtenu une accuracy de 79.74%, ce qui indique \n",
    "que près de 80% des prédictions étaient correctes. La précision de 83.54% souligne la capacité du modèle \n",
    "à prédire précisément les exemples positifs. Le recall élevé de 78.57% signifie que le modèle a réussi \n",
    "à identifier la majorité des vrais positifs parmi les exemples positifs réels. Le F1-score de 80.98% combine \n",
    "ces métriques pour donner une vue équilibrée de la performance du modèle.\n",
    "\n",
    "\n",
    "Transfer Learning : Le modèle de Transfer Learning a surpassé les autres modèles en termes d'accuracy avec 86.09%, \n",
    "indiquant que c'est celui qui a généré le plus grand nombre de prédictions correctes globalement. Avec une précision \n",
    "de 89.47%, il a montré une forte capacité à prédire correctement les exemples positifs. Son recall de 83.61% \n",
    "et son F1-score de 86.44% montrent qu'il a réussi à trouver un équilibre entre la détection des vrais positifs \n",
    "et la minimisation des faux négatifs.\n",
    "\n",
    "\n",
    "Autoencoder : L'Autoencoder a également obtenu des résultats compétitifs avec une accuracy de 75.44%. \n",
    "Sa précision de 77.93% indique une bonne capacité à prédire les exemples positifs, tandis que son recall de 75.44% \n",
    "montre qu'il a identifié la majorité des vrais positifs. Le F1-score de 75.86% reflète un compromis solide \n",
    "entre la précision et le recall.\n",
    "\n",
    "En conclusion, bien que chaque modèle ait ses propres points forts, le modèle de Transfer Learning \n",
    "s'est démarqué en termes d'accuracy globale, tandis que le CNN et l'Autoencoder ont montré des performances \n",
    "équilibrées en termes de précision et de recall. Chacun de ces modèles pourrait être adapté en fonction des priorités\n",
    "spécifiques de la tâche et du compromis souhaité entre la précision et la détection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4caede",
   "metadata": {},
   "source": [
    "# VII.2) Interprétation des résultats pour la classificatoin multiclasse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86757b",
   "metadata": {},
   "source": [
    "Les trois modèles, à savoir le CNN, le Transfer Learning et l'Autoencoder, ont été évalués en termes de leurs performances dans une tâche de classification multiclasse. En comparant leurs métriques clés, nous pouvons observer ce qui suit :\n",
    "\n",
    "\n",
    "\n",
    "CNN : Le modèle Convolutional Neural Network (CNN) a obtenu une accuracy de 71.90%, ce qui indique que près de 72% des prédictions étaient correctes. La précision de 67.90% souligne la capacité du modèle à prédire précisément les exemples positifs. Le recall de 65.05% signifie que le modèle a réussi à identifier plus de la moitié des vrais positifs parmi les exemples positifs réels. Le F1-score de 66.05% combine ces métriques pour donner une vue équilibrée de la performance du modèle.\n",
    "\n",
    "\n",
    "\n",
    "Transfer Learning : Le modèle de Transfer Learning a surpassé les autres modèles en termes d'accuracy avec 81.74%, \n",
    "indiquant que c'est celui qui a généré le plus grand nombre de prédictions correctes globalement. Avec une précision de 81.58%, il a montré une forte capacité à prédire correctement les exemples positifs. Son recall de 81.74% et son F1-score de 81.25% montrent qu'il a réussi à trouver un équilibre entre la détection des vrais positifs et la minimisation des faux négatifs.\n",
    "\n",
    "\n",
    "\n",
    "Autoencoder : L'Autoencoder a également obtenu des résultats compétitifs avec une accuracy de 68.42%. Sa précision de 68.74% indique une bonne capacité à prédire les exemples positifs, tandis que son recall de 68.42% montre qu'il a identifié la majorité des vrais positifs. Le F1-score de 67.83% reflète un compromis solide entre la précision et le recall.\n",
    "\n",
    "\n",
    "En conclusion, bien que chaque modèle ait ses propres points forts, le modèle de Transfer Learning s'est démarqué en termes d'accuracy globale, tandis que le CNN et l'Autoencoder ont montré des performances équilibrées en termes de précision et de recall. Chacun de ces modèles pourrait être adapté en fonction des priorités spécifiques de la tâche et du compromis souhaité entre la précision et la détection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a3dd4",
   "metadata": {},
   "source": [
    "###  VIII ) Comparaison des Performances de l'Autoencoder en Fonction de Deux Approches de Classification en utilisant la Métrique de l'Erreur de Reconstruction (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reconstruction errors for binary classification and multiclass classification\n",
    "reconstruction_error_binary = 0.346050837213107   # Replace with the reconstruction error for binary classification\n",
    "reconstruction_error_multiclass = 0.278545210648486  # Replace with the reconstruction error for multiclass classification\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot reconstruction errors\n",
    "plt.bar(['Binary Classification', 'Multiclass Classification'], [reconstruction_error_binary, reconstruction_error_multiclass], color=['blue', 'green'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error Comparison')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc95dc8",
   "metadata": {},
   "source": [
    "### IX) Interprétation de Comparaison des Performances de l'Autoencoder en Fonction de Deux Approches de Classification en Utilisant la Métrique de l'Erreur de Reconstruction (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "La comparaison entre la classification binaire et multiclasse au niveau de la métrique \n",
    "d'erreur de reconstruction (MSE) révèle que la méthode de classification multiclasse présente\n",
    "une erreur de reconstruction moyenne (MSE) plus faible (0.278545210648486) par rapport \n",
    "à la classification binaire (0.346050837213107). Cela indique que le modèle de classification multiclasse \n",
    "est capable de mieux reconstruire les images d'origine à partir de leurs caractéristiques latentes\n",
    "que le modèle de classification binaire. En d'autres termes, le modèle multiclasse a une meilleure capacité \n",
    "de représentation et de reconstitution des données par rapport au modèle binaire\n",
    "en utilisant l'approche d'autoencodeur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
